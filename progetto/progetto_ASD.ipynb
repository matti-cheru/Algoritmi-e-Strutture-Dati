{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Set, Dict\n",
    "\n",
    "# Definizione del tipo Hypothesis come tupla di interi\n",
    "Hypothesis = Tuple[int, ...]\n",
    "\n",
    "\n",
    "def empty_hypothesis(n: int):\n",
    "    \"\"\"Crea un'ipotesi vuota di lunghezza n.\"\"\"\n",
    "    return tuple([0]*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successore_immediato(h: Hypothesis):\n",
    "    \"\"\"\n",
    "    Restituisce la lista di tutte le ipotesi che \n",
    "    differiscono da h per un solo bit (da 0 a 1)\n",
    "    :param h: ipotesi di partenza\n",
    "    :return: lista di ipotesi successori\n",
    "    \"\"\"\n",
    "    successori = []\n",
    "    h_list = list(h)\n",
    "    for i in range(len(h_list)):\n",
    "        if h_list[i] == 0:\n",
    "            nuovo = h_list.copy()\n",
    "            nuovo[i] = 1\n",
    "            successori.append(nuovo)\n",
    "    return successori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecessore_immediato(h: Hypothesis):\n",
    "    \"\"\"\n",
    "    Il numero di predecessori immediati corrisponde al numero di 1 in h\n",
    "    :param h: ipotesi di partenza\n",
    "    :return: lista di ipotesi predecessori\n",
    "    \"\"\"\n",
    "    predecessori = []\n",
    "    for i in reversed(range(len(h))):  # Scorri gli indici al contrario\n",
    "        if h[i] == 1:\n",
    "            nuovo = list(h)\n",
    "            nuovo[i] = 0\n",
    "            predecessori.append(tuple(nuovo))\n",
    "    return predecessori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SET_FIELDS(h):\n",
    "    \"\"\"Metodo per impostare il campo vector(h) di un'ipotesi h.\n",
    "    :param h: ipotesi di cui si vuole impostare il campo vector\n",
    "    \"\"\"\n",
    "    ipotesi_vuota = empty_hypothesis(len(h))\n",
    "    successori = successore_immediato(ipotesi_vuota)\n",
    "    if list(h) in successori:\n",
    "        vector_h = list(h)\n",
    "    else:\n",
    "        vector_h = [0] * len(h)\n",
    "    return vector_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PROPAGATE(h: Hypothesis, h1: Hypothesis):\n",
    "    \"\"\"\n",
    "    Propaga le informazioni dall'ipotesi h1 all'ipotesi h.\n",
    "    :param h: ipotesi di partenza\n",
    "    :param h1: ipotesi da cui propagare le informazioni\n",
    "    :return: nuova ipotesi risultante dalla propagazione\n",
    "    \"\"\"\n",
    "    risultato = tuple(x | y for x, y in zip(h, h1))\n",
    "\n",
    "    return risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LM1(h: Hypothesis) -> int:\n",
    "    \"\"\"\n",
    "    Restituisce la posizione (indice) del primo 1 nella tupla h.\n",
    "    Se non c'è nessun 1, restituisce -1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return h.index(1)+1\n",
    "    except ValueError:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalInitial(h: Hypothesis):\n",
    "    \"\"\"\n",
    "    Metodo che restituisce l'ipotesi iniziale globale.\n",
    "    :param h: ipotesi di partenza\n",
    "    :return: ipotesi iniziale globale\n",
    "    \"\"\"\n",
    "    h_list = list(h)\n",
    "    if not all(x == 0 for x in h_list) and h_list[0] == 0:\n",
    "        h_list[0] = 1\n",
    "        for i in range(len(h_list)-1, 0, -1):\n",
    "            if h_list[i] == 1:\n",
    "                h_list[i] = 0\n",
    "                break\n",
    "        return tuple(h_list)\n",
    "    return tuple(h_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial(h: Hypothesis, h1: Hypothesis):\n",
    "    \"\"\"\n",
    "    Restituisce il predecessore immediato di h1\n",
    "    più a sinistra tra tutti i predecessori immediati di h1\n",
    "    distinti da h\n",
    "    :param h: ipotesi di partenza\n",
    "    :param h1: ipotesi di cui si vogliono trovare i predecessori\n",
    "    :return: predecessore immediato di h1 più a sinistra\n",
    "    \"\"\"\n",
    "    predecessori = predecessore_immediato(h1)\n",
    "    return predecessori[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(h: Hypothesis, h1: Hypothesis):\n",
    "    \"\"\"\n",
    "    Restituisce il predecessore immediato di h1\n",
    "    più a destra tra tutti i predecessori immediati di h1\n",
    "    distinti da h\n",
    "    :param h: ipotesi di partenza\n",
    "    :param h1: ipotesi di cui si vogliono trovare i predecessori\n",
    "    :return: predecessore immediato di h1 più a destra\n",
    "    \"\"\"\n",
    "    predecessori = predecessore_immediato(h1)\n",
    "    return predecessori[len(predecessori)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(h: Hypothesis, h1: Hypothesis) -> int:\n",
    "    \"\"\"\n",
    "    Calcola la distanza tra due ipotesi h e h1\n",
    "    :param h: ipotesi di partenza\n",
    "    :param h1: ipotesi di arrivo\n",
    "    :return: distanza tra h e h1\n",
    "    \"\"\"\n",
    "    return sum(el1 != el2 for el1, el2 in zip(h, h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(h: Hypothesis) -> int:\n",
    "    \"\"\"\n",
    "    Calcola la cardinalità di un'ipotesi h, intesa come numero di 1 in h\n",
    "    :param h: ipotesi di cui si vuole calcolare la cardinalità\n",
    "    :return: cardinalità di h\n",
    "    \"\"\"\n",
    "    return sum(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binario(h: Hypothesis) -> int:\n",
    "    \"\"\"\n",
    "    Restituisce il valore intero corrispondente alla rappresentazione binaria di h\n",
    "    :param h: ipotesi da convertire in intero\n",
    "    :return: valore intero corrispondente a h\n",
    "    \"\"\"\n",
    "    return int(\"\".join(map(str, h)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MERGE(seq1: List[Hypothesis], seq2: List[Hypothesis]) -> List[Hypothesis]:\n",
    "    \"\"\"\n",
    "    Unisce due liste ordinate di ipotesi in un'unica lista ordinata,\n",
    "    confrontando con la funzione binario(h).\n",
    "    :param seq1: prima lista di ipotesi ordinate\n",
    "    :param seq2: seconda lista di ipotesi ordinate\n",
    "    :return: lista unita di ipotesi ordinate\n",
    "    \"\"\"\n",
    "    i, j = 0, 0\n",
    "    merged = []\n",
    "    \n",
    "    while i < len(seq1) and j < len(seq2):\n",
    "        if binario(seq1[i]) <= binario(seq2[j]):\n",
    "            merged.append(seq1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            merged.append(seq2[j])\n",
    "            j += 1\n",
    "    \n",
    "    # aggiungo gli elementi rimanenti\n",
    "    while i < len(seq1):\n",
    "        merged.append(seq1[i])\n",
    "        i += 1\n",
    "    while j < len(seq2):\n",
    "        merged.append(seq2[j])\n",
    "        j += 1\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHECK(h: Hypothesis, N: List[List[str]], M: List[str]):\n",
    "    \"\"\"\n",
    "    Controlla se un ipotesi h è una soluzione per il problema\n",
    "    :param h: ipotesi da controllare\n",
    "    :param N: lista di liste di stringhe, dove ogni lista interna rappresenta un\n",
    "    insieme di stringhe che devono essere hittati dall'ipotesi h\n",
    "    :param M: lista di stringhe che rappresentano gli elementi associati agli indici\n",
    "    di h\n",
    "    \"\"\"\n",
    "    for lista_interna in N:\n",
    "        if not any(h[i] == 1 and M[i] in lista_interna for i in range(len(M))):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_minimal(h, solutions):\n",
    "    \"\"\"\n",
    "    Metodo che controlla se un'ipotesi h è minimale\n",
    "    rispetto a una lista di soluzioni\n",
    "    :param h: ipotesi da controllare\n",
    "    :param solutions: lista di soluzioni\n",
    "    :return: True se h è minimale, False altrimenti\n",
    "    \"\"\"\n",
    "    for other in solutions:\n",
    "        if other != h:\n",
    "            # se other è sottoinsieme di h\n",
    "            if all((h[i] >= other[i]) for i in range(len(h))) and any(h[i] > other[i] for i in range(len(h))):\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(matrix: List[List[int]]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Restituisce la trasposizione della matrice data.\n",
    "    :param matrix: matrice da trasporre\n",
    "    :return: matrice trasposta\n",
    "    \"\"\"\n",
    "    if not matrix:\n",
    "        return []\n",
    "    return [list(row) for row in zip(*matrix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matrix_files(path):\n",
    "    M = []   # domini (colonne)\n",
    "    N = []   # insiemi (righe)\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # --- 1) Trova la riga con \"Map\"\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\";;; Map\"):\n",
    "            parts = line.strip().split()[2:]  # salta \";;; Map\"\n",
    "            for p in parts:\n",
    "                idx, name = p.split(\"(\")\n",
    "                name = name.strip(\")\")\n",
    "                M.append(name)\n",
    "            break\n",
    "\n",
    "    # --- 2) Trova le righe numeriche\n",
    "    for line in lines:\n",
    "        if line.strip() and line[0].isdigit():\n",
    "            values = line.strip().split()\n",
    "            if values[-1] == \"-\":\n",
    "                values = values[:-1]\n",
    "\n",
    "            length = min(len(values), len(M))\n",
    "            # lista ordinata di nomi corrispondenti a 1\n",
    "            subset = [M[i] for i, v in enumerate(values[:length]) if v == \"1\"]\n",
    "            N.append(subset)\n",
    "\n",
    "    return M, N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_filename(path: str, with_extension: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Estrae il nome del file dal percorso completo.\n",
    "    :param path: percorso completo del file\n",
    "    :param with_extension: se True, include l'estensione del file\n",
    "    :return: nome del file\n",
    "    \"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    if not with_extension:\n",
    "        base = os.path.splitext(base)[0]\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominio M: ['z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11', 'z12', 'z13', 'z14', 'z15', 'z16', 'z17', 'z18', 'z19', 'z20', 'z21', 'z22', 'z23', 'z24', 'z25', 'z26', 'z27', 'z28', 'z29', 'z30', 'o1', 'o2', 'o3']\n",
      "Insiemi N:\n",
      "  N1 = ['z4', 'z9', 'z10', 'z17', 'z22', 'z24', 'o2']\n",
      "  N2 = ['z2', 'z22', 'o2']\n"
     ]
    }
   ],
   "source": [
    "M, N = parse_matrix_files(\"../benchmarks1/74L85.000.matrix\")\n",
    "\n",
    "print(\"Dominio M:\", M)\n",
    "print(\"Insiemi N:\")\n",
    "for i, subset in enumerate(N, 1):\n",
    "    print(f\"  N{i} = {subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GENERATE_CHILDREN(h: Hypothesis, current: List[Hypothesis]):\n",
    "    children = set()\n",
    "\n",
    "    # Caso: ipotesi vuota → genera tutti i vicini a distanza 1\n",
    "    if h == empty_hypothesis(len(h)):\n",
    "        for i in range(len(h)):\n",
    "            if h[i] == 0:\n",
    "                h1 = list(h)\n",
    "                h1[i] = 1\n",
    "                SET_FIELDS(h1)\n",
    "                children.add(tuple(h1))\n",
    "        return list(children)\n",
    "\n",
    "    # Mappa per accesso rapido agli indici\n",
    "    index_map = {tuple(hyp): idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "    for i in range(LM1(h) - 1):\n",
    "        if h[i] == 0:\n",
    "            h1 = list(h)\n",
    "            h1[i] = 1\n",
    "            SET_FIELDS(h1)\n",
    "            PROPAGATE(h, h1)\n",
    "\n",
    "            h_i = initial(h, h1)\n",
    "            h_f = final(h, h1)\n",
    "            count = 0\n",
    "\n",
    "            # prendo indici in sicurezza\n",
    "            start_idx = index_map.get(tuple(h_f), 0)\n",
    "            end_idx   = index_map.get(tuple(h_i), len(current) - 1)\n",
    "\n",
    "            # scorro su una sottolista di current SENZA modificarla\n",
    "            for hp in current[start_idx:end_idx + 1]:\n",
    "                if dist(hp, h1) == 1 and dist(hp, h) == 2:\n",
    "                    PROPAGATE(hp, h1)\n",
    "                    count += 1\n",
    "\n",
    "            if count == card(h) and tuple(h1) != tuple(h):\n",
    "                children.add(tuple(h1))\n",
    "\n",
    "    return list(children)\n",
    "# TEST 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versione corretta ma teniamo anche l'altra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GENERATE_CHILDREN(h: Hypothesis, current: List[Hypothesis]):\n",
    "    \"\"\"\n",
    "    Genera i figli dell'ipotesi h secondo la logica originale.\n",
    "    :param h: ipotesi di partenza\n",
    "    :param current: lista delle ipotesi correnti\n",
    "    :return: lista di ipotesi figlie\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Caso ipotesi vuota → genera tutti i successori immediati\n",
    "    if card(h) == 0:\n",
    "        for i in range(len(h)):\n",
    "            if h[i] == 0:\n",
    "                h1 = list(h)\n",
    "                h1[i] = 1\n",
    "                children.append(tuple(h1))\n",
    "        return children\n",
    "\n",
    "    # Creazione mappa per accesso rapido\n",
    "    index_map = {hyp: idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "    # Scorri fino al leftmost 1 di h\n",
    "    for i in range(LM1(h) - 1):\n",
    "        if h[i] == 0:\n",
    "            h1 = list(h)\n",
    "            h1[i] = 1\n",
    "            # Propagazione\n",
    "            h1 = PROPAGATE(h, tuple(h1))\n",
    "\n",
    "            h_i = initial(h, tuple(h1))\n",
    "            h_f = final(h, tuple(h1))\n",
    "\n",
    "            # Indici nella lista corrente\n",
    "            start_idx = index_map.get(h_f, 0)\n",
    "            end_idx = index_map.get(h_i, len(current) - 1)\n",
    "\n",
    "            count = 0\n",
    "            for hp in current[start_idx:end_idx + 1]:\n",
    "                if dist(hp, tuple(h1)) == 1 and dist(hp, h) == 2:\n",
    "                    h1 = PROPAGATE(hp, tuple(h1))\n",
    "                    count += 1\n",
    "\n",
    "            if count == card(h) and tuple(h1) != tuple(h):\n",
    "                children.append(tuple(h1))\n",
    "\n",
    "    return children\n",
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def MAIN(N: List[List[str]], M: List[str], input_path:str, max_seconds: int = None, output_dir: str = \"compito_1/outputs\"):\n",
    "    start_time = time.time() # tempo di inizio\n",
    "\n",
    "    h_0 = tuple(empty_hypothesis(len(M)))\n",
    "    current = [h_0]\n",
    "    solutions = set()\n",
    "\n",
    "    # Variabili per gestione timeout\n",
    "    interrupted = False\n",
    "    interrupted_level = None\n",
    "\n",
    "    while current:\n",
    "        next_level = []\n",
    "\n",
    "        for h in list(current):\n",
    "            # Controllo timeout\n",
    "            if max_seconds and (time.time() - start_time) > max_seconds:\n",
    "                interrupted = True\n",
    "                interrupted_level = card(h)\n",
    "                current = []  # forza uscita dal while\n",
    "                break\n",
    "\n",
    "            # Controllo se h è una soluzione\n",
    "            if CHECK(h, N, M):\n",
    "                solutions.add(h)\n",
    "                current.remove(h)\n",
    "\n",
    "            elif h == empty_hypothesis(len(M)):\n",
    "                next_level.extend(GENERATE_CHILDREN(h, current))\n",
    "\n",
    "            elif LM1(h) != 1:\n",
    "                h_s_2 = globalInitial(h)\n",
    "\n",
    "                # Rimuovi da current tutte le ipotesi h_r tali che bin(h_r) > bin(h_s_2)\n",
    "                current = [h_r for h_r in current if binario(h_r) <= binario(h_s_2)]\n",
    "\n",
    "                # Prendo la prima ipotesi in current\n",
    "                if current:\n",
    "                    h_p = current[0]\n",
    "                    if h_p != h:\n",
    "                        next_level = MERGE(next_level, GENERATE_CHILDREN(h, current))\n",
    "        \n",
    "        current = next_level\n",
    "        minimal_solutions = [h for h in solutions if is_minimal(h, solutions)]\n",
    "        \n",
    "\n",
    "    # --- Prepara directory di output ---\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Nome del file in uscita\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    output_path = os.path.join(output_dir, base_name + \".mhs\")\n",
    "\n",
    "    # --- Scrittura file ---\n",
    "    with open(output_path, \"w\") as f:\n",
    "        # intestazione\n",
    "        f.write(f\";;; Generated from {os.path.basename(input_path)}\\n\")\n",
    "        f.write(f\";;; MHS computation\\n\")\n",
    "\n",
    "        # Map (colonne come nel file originale)\n",
    "        f.write(\";;; Map \" + \" \".join(f\"{i+1}({M[i]})\" for i in range(len(M))) + \"\\n\")\n",
    "\n",
    "        # scrivi i MHS in formato matriciale\n",
    "        for sol in minimal_solutions:\n",
    "            row = \" \".join(str(x) for x in sol) + \" -\"\n",
    "            f.write(row + \"\\n\")\n",
    "\n",
    "        # --- Riassunto ---\n",
    "        f.write(\";;;\\n\")\n",
    "        f.write(f\";;; Input matrix size: {len(N)} x {len(M)}\\n\")\n",
    "        f.write(f\";;; Number of MHS: {len(minimal_solutions)}\\n\")\n",
    "\n",
    "        if minimal_solutions:\n",
    "            min_card = min(card(h) for h in minimal_solutions)\n",
    "            max_card = max(card(h) for h in minimal_solutions)\n",
    "            f.write(f\";;; Min cardinality: {min_card}\\n\")\n",
    "            f.write(f\";;; Max cardinality: {max_card}\\n\")\n",
    "\n",
    "        if interrupted:\n",
    "            f.write(f\";;; Computation interrupted (timeout {max_seconds}s)\\n\")\n",
    "            f.write(f\";;; Interrupted at level H = {interrupted_level}\\n\")\n",
    "\n",
    "    return minimal_solutions, output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova per vedere se funziona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominio M: ['z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11', 'z12', 'z13', 'z14', 'z15', 'z16', 'z17', 'z18', 'z19', 'z20', 'z21', 'z22', 'z23', 'z24', 'z25', 'z26', 'z27', 'z28', 'z29', 'z30', 'o1', 'o2', 'o3']\n",
      "Insiemi N:\n",
      "  N1 = ['z1', 'z2', 'z5', 'z9', 'z10', 'z11', 'z12', 'z17', 'z18', 'z24', 'z25', 'o2', 'o3']\n",
      "  N2 = ['z1', 'z4', 'z9', 'z10', 'z17', 'z22', 'z24', 'o2']\n",
      "  N3 = ['z2', 'z4', 'z9', 'z10', 'z17', 'z21', 'z24', 'o2', 'o3']\n",
      "  N4 = ['z1', 'z2', 'z4', 'z9', 'z10', 'z17', 'z24', 'o2']\n"
     ]
    }
   ],
   "source": [
    "# --- parsing del file .matrix ---\n",
    "# M, N = parse_matrix_files(\"../benchmarks1/74L85.000.matrix\")\n",
    "# M, N = parse_matrix_files(\"../benchmarks1/74L85.008.matrix\")\n",
    "M, N = parse_matrix_files(\"../benchmarks1/74L85.002.matrix\")\n",
    "\n",
    "print(\"Dominio M:\", M)\n",
    "print(\"Insiemi N:\")\n",
    "for i, subset in enumerate(N, 1):\n",
    "    print(f\"  N{i} = {subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero di MHS trovati: 5\n",
      "File di output generato: compito_1/outputs/74L85.002.mhs\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0) -> ['o2']\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0) -> ['z24']\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) -> ['z9']\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) -> ['z10']\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) -> ['z17']\n"
     ]
    }
   ],
   "source": [
    "# --- esecuzione algoritmo MAIN con output in ./outputs ---\n",
    "# solutions, output_file = MAIN(N, M, \"../benchmarks1/74L85.000.matrix\", max_seconds=30) # test completo\n",
    "# solutions, output_file = MAIN(N, M, \"../benchmarks1/74L85.008.matrix\", max_seconds=0.6) # test per interruzione\n",
    "solutions, output_file = MAIN(N, M, \"../benchmarks1/74L85.002.matrix\", max_seconds=120)\n",
    "\n",
    "\n",
    "print(\"\\nNumero di MHS trovati:\", len(solutions))\n",
    "print(\"File di output generato:\", output_file)\n",
    "\n",
    "# Se vuoi dare un'occhiata rapida ai primi MHS trovati.\n",
    "for s in solutions:\n",
    "    elementi = [M[i] for i, bit in enumerate(s) if bit == 1]\n",
    "    print(f\"{s} -> {elementi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compito 2 (Update 22/09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_domain_remove_empty_cols(M: List[str], N: List[Set[str]]):\n",
    "    \"\"\"\n",
    "    Rimuove colonne di M che non compaiono in alcun subset di N.\n",
    "    Restituisce:\n",
    "      - M_prime: lista colonne non vuote (ordine preservato)\n",
    "      - N_prime: lista di set coerenti con M_prime\n",
    "      - removed_indices: lista di indici originali (0-based) rimossi\n",
    "      - old_to_new: lista di lunghezza len(M) con -1 per rimossi, altrimenti indice in M_prime\n",
    "      - new_to_old: lista di indici originali per ogni indice di M_prime\n",
    "    \"\"\"\n",
    "    name_to_index = {name: i for i, name in enumerate(M)}   # mappa nome -> indice\n",
    "    used = [False] * len(M)                                 # tracciamento colonne usate\n",
    "\n",
    "    for subset in N:\n",
    "        for name in subset:\n",
    "            idx = name_to_index.get(name)\n",
    "            if idx is not None:\n",
    "                used[idx] = True\n",
    "\n",
    "    removed_indices = [i for i, u in enumerate(used) if not u]      # indici rimossi\n",
    "    new_to_old = [i for i, u in enumerate(used) if u]       \n",
    "    old_to_new = [-1] * len(M)  \n",
    "    for new_idx, old_idx in enumerate(new_to_old):                  \n",
    "        old_to_new[old_idx] = new_idx\n",
    "\n",
    "    M_prime = [M[i] for i in new_to_old]    # colonne non vuote di M\n",
    "\n",
    "    # costruisco N_prime mantenendo solo nomi presenti in M_prime\n",
    "    N_prime = []\n",
    "    for subset in N:\n",
    "        subset_prime = {name for name in subset if name in name_to_index and old_to_new[name_to_index[name]] != -1}\n",
    "        N_prime.append(subset_prime)\n",
    "\n",
    "    return M_prime, N_prime, removed_indices, old_to_new, new_to_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_solution_to_full(sol_reduced: Tuple[int, ...], M_len: int, old_to_new: List[int]):\n",
    "    \"\"\"\n",
    "    Rialza una soluzione su M' (tupla len(M')) alla rappresentazione completa len(M),\n",
    "    inserendo 0 nelle colonne rimosse.\n",
    "    :param sol_reduced: soluzione su M' (tupla di 0/1)\n",
    "    :param M_len: lunghezza originale di M\n",
    "    :param old_to_new: mappa da indici originali a nuovi indici (-1 se rimosso)\n",
    "    :return: tupla di lunghezza M_len con 0\n",
    "    \"\"\"\n",
    "    full = [0] * M_len  # soluzione completa inizializzata a 0\n",
    "    for old_idx, new_idx in enumerate(old_to_new):      # scorro indici originali\n",
    "        if new_idx != -1:                               # controllo se non è stato rimosso   \n",
    "            full[old_idx] = sol_reduced[new_idx]        \n",
    "        else:\n",
    "            full[old_idx] = 0\n",
    "    return tuple(full)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import time\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "try:                            \n",
    "    import psutil               # libreria per monitorare utilizzo della memoria\n",
    "    _HAS_PSUTIL = True\n",
    "except Exception:\n",
    "    _HAS_PSUTIL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_perf_tracking():\n",
    "    \"\"\"Avvia tracciamento memoria (tracemalloc) e prende tempo iniziale.\"\"\"\n",
    "    tracemalloc.start()\n",
    "    return time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_perf_tracking(start_time: float):\n",
    "    \"\"\"Ferma tracemalloc e ritorna elapsed_seconds, peak_mem_kb.\"\"\"\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    elapsed = time.perf_counter() - start_time  # tempo trascorso in secondi\n",
    "    peak_kb = int(peak / 1024) if peak is not None else None    # picco memoria in KB \n",
    "\n",
    "    # se psutil disponibile forniamo anche rss come fallback\n",
    "    rss_kb = None\n",
    "    if _HAS_PSUTIL:\n",
    "        p = psutil.Process(os.getpid())\n",
    "        try:\n",
    "            rss_kb = int(p.memory_info().rss / 1024)\n",
    "        except Exception:\n",
    "            rss_kb = None\n",
    "\n",
    "    return elapsed, peak_kb, rss_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mhs_file(output_path: str,\n",
    "                   input_basename: str,\n",
    "                   M: List[str],\n",
    "                   minimal_solutions_full: List[Tuple[int, ...]],\n",
    "                   stats: dict,\n",
    "                   removed_indices_1based: Optional[List[int]] = None):\n",
    "    \"\"\"Metodo per scrivere il file .mhs con intestazione e riepilogo.\n",
    "    :param output_path: percorso completo del file di output\n",
    "    :param input_basename: nome del file di input (solo nome, senza path)\n",
    "    :param M: lista completa delle colonne (dominio originale)\n",
    "    :param minimal_solutions_full: lista di tuple rappresentanti le soluzioni su M completo\n",
    "    :param stats: dizionario con statistiche da includere nel file\n",
    "    :param removed_indices_1based: lista di indici (1-based) delle colonne rimosse\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path) or \".\", exist_ok=True)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(f\";;; Generated from {input_basename}\\n\")\n",
    "        f.write(\";;; MHS computation\\n\")\n",
    "        f.write(f\";;; Input matrix {stats.get('len_N')} X {stats.get('len_M')}\\n\")\n",
    "        f.write(f\";;; Number of MHS found: {stats.get('total_solutions_found')}\\n\")\n",
    "        f.write(f\";;; Minimum cardinality: {stats.get('min_cardinality')}\\n\")\n",
    "        f.write(f\";;; Maximum cardinality: {stats.get('max_cardinality')}\\n\")\n",
    "        f.write(f\";;; Elapsed time: {stats.get('elapsed_seconds')}s\\n\")\n",
    "        f.write(f\";;; Memory used: {stats.get('peak_mem_kb')} KB\\n\")\n",
    "\n",
    "        # Colonne rimosse\n",
    "        if removed_indices_1based:\n",
    "            f.write(f\";;; Computation done removing the columns: {removed_indices_1based}\\n\")\n",
    "            f.write(f\";;; -> The dimensions of the matrix really used are {stats.get('len_N')} X {stats.get('len_Mp')}\\n\")\n",
    "        else:\n",
    "            f.write(f\";;; Computation done without removing columns\\n\")\n",
    "\n",
    "        # Livello di interruzione (se presente)\n",
    "        if stats.get(\"interrupted\"):\n",
    "            f.write(f\";;; Computation stopped at level {stats.get('interrupted_level')}\\n\")\n",
    "        else:\n",
    "            f.write(f\";;; Computation completed successfully\\n\")\n",
    "        \n",
    "        f.write(\";;;\\n\")\n",
    "        f.write(\";;; Hypotesis generated for each level:\\n\")\n",
    "\n",
    "        # --- Statistiche per livello ---\n",
    "        level_stats = stats.get(\"level_stats\", {})\n",
    "        for lvl in sorted(level_stats.keys()):\n",
    "            g = level_stats[lvl].get(\"generated\", 0)\n",
    "            label = \"hypotesis\" if g == 1 else \"hypoteses\"\n",
    "            f.write(f\";;; Level {lvl}: {g} {label}\\n\")\n",
    "\n",
    "        f.write(\";;;\\n\")\n",
    "    \n",
    "        f.write(\";;; Map \" + \" \".join(f\"{i+1}({M[i]})\" for i in range(len(M))) + \"\\n\")\n",
    "\n",
    "        # --- Scrittura delle soluzioni ---\n",
    "        for sol in minimal_solutions_full:\n",
    "            f.write(\" \".join(str(x) for x in sol) + \" -\\n\")\n",
    "                \n",
    "    print(f\"[INFO] File scritto correttamente: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST 2.1\n",
    "def GENERATE_CHILDREN(h: Hypothesis, current: List[Hypothesis]):\n",
    "    \"\"\"\n",
    "    Genera i figli dell'ipotesi h in ordine decrescente binaria.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Caso ipotesi vuota → genera tutti i successori immediati\n",
    "    if card(h) == 0:\n",
    "        for i in reversed(range(len(h))):\n",
    "            if h[i] == 0:\n",
    "                h1 = list(h)\n",
    "                h1[i] = 1\n",
    "                children.append(tuple(h1))\n",
    "        return children\n",
    "\n",
    "    # Creazione mappa per accesso rapido\n",
    "    index_map = {hyp: idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "    # Scorri tutti i bit da destra verso sinistra fino al leftmost 1\n",
    "    for i in reversed(range(LM1(h))):\n",
    "        if h[i] == 0:\n",
    "            h1 = list(h)\n",
    "            h1[i] = 1\n",
    "            h1 = PROPAGATE(h, tuple(h1))\n",
    "\n",
    "            h_i = initial(h, tuple(h1))\n",
    "            h_f = final(h, tuple(h1))\n",
    "\n",
    "            start_idx = index_map.get(h_f, 0)\n",
    "            end_idx = index_map.get(h_i, len(current) - 1)\n",
    "\n",
    "            count = 0\n",
    "            for hp in current[start_idx:end_idx + 1]:\n",
    "                if dist(hp, tuple(h1)) == 1 and dist(hp, h) == 2:\n",
    "                    h1 = PROPAGATE(hp, tuple(h1))\n",
    "                    count += 1\n",
    "\n",
    "            if count == card(h) and tuple(h1) != tuple(h):\n",
    "                children.append(tuple(h1))\n",
    "\n",
    "    # Già in ordine decrescente, non serve ulteriore sort\n",
    "    return children\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versione corretta Generate Children ripresa da sopra dove c'è scritto #TEST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GENERATE_CHILDREN(h: Hypothesis, current: List[Hypothesis]):\n",
    "    \"\"\"\n",
    "    Genera i figli dell'ipotesi h secondo la logica originale.\n",
    "    :param h: ipotesi di partenza\n",
    "    :param current: lista delle ipotesi correnti\n",
    "    :return: lista di ipotesi figlie\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Caso ipotesi vuota → genera tutti i successori immediati\n",
    "    if card(h) == 0:\n",
    "        for i in range(len(h)):\n",
    "            if h[i] == 0:\n",
    "                h1 = list(h)\n",
    "                h1[i] = 1\n",
    "                children.append(tuple(h1))\n",
    "        return children\n",
    "\n",
    "    # Creazione mappa per accesso rapido\n",
    "    index_map = {hyp: idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "    # Scorri fino al leftmost 1 di h\n",
    "    for i in range(LM1(h) - 1):\n",
    "        if h[i] == 0:\n",
    "            h1 = list(h)\n",
    "            h1[i] = 1\n",
    "            # Propagazione\n",
    "            h1 = PROPAGATE(h, tuple(h1))\n",
    "\n",
    "            h_i = initial(h, tuple(h1))\n",
    "            h_f = final(h, tuple(h1))\n",
    "\n",
    "            # Indici nella lista corrente\n",
    "            start_idx = index_map.get(h_f, 0)\n",
    "            end_idx = index_map.get(h_i, len(current) - 1)\n",
    "\n",
    "            count = 0\n",
    "            for hp in current[start_idx:end_idx + 1]:\n",
    "                if dist(hp, tuple(h1)) == 1 and dist(hp, h) == 2:\n",
    "                    h1 = PROPAGATE(hp, tuple(h1))\n",
    "                    count += 1\n",
    "\n",
    "            if count == card(h) and tuple(h1) != tuple(h):\n",
    "                children.append(tuple(h1))\n",
    "\n",
    "    return children\n",
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAIN_COMPITO_2(input_path: str, max_seconds: float = None, output_dir: str = \"outputs\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Wrapper MAIN:\n",
    "      - legge M,N dal file (parse_matrix_file)\n",
    "      - riduce dominio a M'\n",
    "      - esegue la ricerca MHS su M' (utilizza le funzioni CHECK/GENERATE_CHILDREN/... già presenti)\n",
    "      - registra statistiche temporali/spaziali e per-livello\n",
    "      - scrive file .mhs in output_dir con soluzioni rialzate su M\n",
    "    :param input_path: percorso completo del file .matrix di input\n",
    "    :param max_seconds: timeout in secondi (None = nessun timeout)\n",
    "    :param output_dir: directory di output per il file .mhs\n",
    "    :return: (minimal_solutions_full, output_path, stats)\n",
    "        - minimal_solutions_full: lista di tuple rappresentanti le soluzioni su M completo\n",
    "        - output_path: percorso completo del file .mhs generato\n",
    "        - stats: dizionario con statistiche della computazione\n",
    "    \"\"\"\n",
    "\n",
    "    # --- parsing del file di input e riduzione delle colonne vuote ---\n",
    "    M, N = parse_matrix_files(input_path)          # M: List[str], N: List[Set[str]]\n",
    "    len_M = len(M)\n",
    "    len_N = len(N)\n",
    "\n",
    "    M_prime, N_prime, removed_indices, old_to_new, new_to_old = reduce_domain_remove_empty_cols(M, N)\n",
    "    len_Mp = len(M_prime)\n",
    "\n",
    "    # Livello H_max = max(len_N, len_Mp)\n",
    "    H_max = max(len_N, len_Mp)\n",
    "\n",
    "    # Conversione liste per la funzione CHECK\n",
    "    N_list_prime = [list(s) for s in N_prime]\n",
    "    M_prime_list = list(M_prime)\n",
    "\n",
    "    # dizionario per statistiche\n",
    "    stats: Dict = {\n",
    "        \"input_file\": os.path.basename(input_path),\n",
    "        \"len_M\": len_M,\n",
    "        \"len_Mp\": len_Mp,\n",
    "        \"len_N\": len_N,\n",
    "        \"removed_indices\": removed_indices,\n",
    "        \"H_max\": H_max,\n",
    "        \"elapsed_seconds\": None,\n",
    "        \"peak_mem_kb\": None,\n",
    "        \"interrupted\": False,\n",
    "        \"interrupted_level\": None,\n",
    "        \"max_seconds\": max_seconds,\n",
    "        \"level_stats\": {}, \n",
    "        \"total_solutions_found\": 0,\n",
    "        \"min_cardinality\": None,\n",
    "        \"max_cardinality\": None,\n",
    "    }\n",
    "\n",
    "    # --- start perf tracking ---\n",
    "    start_time = start_perf_tracking()\n",
    "    stats[\"start_time\"] = start_time\n",
    "    stats[\"start_time_str\"] = time.ctime()\n",
    "\n",
    "\n",
    "    h_0 = empty_hypothesis(len_Mp)\n",
    "    current: List[Hypothesis] = [h_0]\n",
    "    solutions_reduced: Set[Hypothesis] = set()\n",
    "\n",
    "    # timeout flags\n",
    "    interrupted = False\n",
    "    interrupted_level = None\n",
    "\n",
    "    level_stats: Dict[int, Dict[str, int]] = {} \n",
    "\n",
    "    # --- ciclo principale algoritmo ---\n",
    "    try:\n",
    "        while current:\n",
    "            next_level: List[Hypothesis] = []\n",
    "\n",
    "            for h in list(current):\n",
    "                # timeout\n",
    "                if max_seconds and (time.perf_counter() - start_time) > max_seconds:\n",
    "                    interrupted = True\n",
    "                    interrupted_level = card(h)\n",
    "                    current = []  # forza uscita\n",
    "                    break\n",
    "\n",
    "                lvl = card(h)\n",
    "                level_stats.setdefault(lvl, {\"generated\": 0, \"checked\": 0})\n",
    "                level_stats[lvl][\"checked\"] += 1\n",
    "\n",
    "                # prune: non generare figli oltre H_max\n",
    "                if lvl >= H_max:\n",
    "                    # verifico se è soluzione su dominio ridotto \n",
    "                    if CHECK(h, N_list_prime, M_prime_list):\n",
    "                        solutions_reduced.add(h)\n",
    "                    continue\n",
    "\n",
    "                # verifica soluzione su dominio ridotto\n",
    "                if CHECK(h, N_list_prime, M_prime_list):\n",
    "                    solutions_reduced.add(h)\n",
    "                    try:\n",
    "                        current.remove(h)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                elif h == empty_hypothesis(len_Mp):\n",
    "                    children = GENERATE_CHILDREN(h, current)\n",
    "                    nxt_level = lvl + 1\n",
    "                    level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                    level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                    next_level.extend(children)\n",
    "\n",
    "                elif LM1(h) != 1:\n",
    "                    h_s_2 = globalInitial(h)\n",
    "                    # filtra current\n",
    "                    current = [h_r for h_r in current if binario(h_r) <= binario(h_s_2)]\n",
    "\n",
    "                    if current:\n",
    "                        h_p = current[0]\n",
    "                        if h_p != h:\n",
    "                            children = GENERATE_CHILDREN(h, current)\n",
    "                            nxt_level = lvl + 1\n",
    "                            level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                            level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                            next_level = MERGE(next_level, children)\n",
    "\n",
    "            # livello successivo esplorazione\n",
    "            current = next_level\n",
    "            stats[\"level_stats\"] = level_stats\n",
    "\n",
    "            # controllo interruzione per statistiche\n",
    "            if interrupted: \n",
    "                stats[\"interrupted\"] = True\n",
    "                stats[\"interrupted_level\"] = interrupted_level\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        interrupted = True\n",
    "        stats[\"exception\"] = repr(e)\n",
    "\n",
    "    # --- end tracking ---\n",
    "    elapsed, peak_kb, rss_kb = stop_perf_tracking(start_time)\n",
    "    stats[\"end_time\"] = time.perf_counter()\n",
    "    stats[\"end_time_str\"] = time.ctime()\n",
    "    stats[\"elapsed_seconds\"] = elapsed\n",
    "    stats[\"peak_mem_kb\"] = peak_kb\n",
    "    stats[\"rss_kb\"] = rss_kb\n",
    "    stats[\"interrupted\"] = interrupted\n",
    "    stats[\"interrupted_level\"] = interrupted_level\n",
    "    stats[\"level_stats\"] = level_stats\n",
    "\n",
    "    # --- estrai MHS e rialza su dominio M originale ---\n",
    "    minimal_solutions_reduced = [h for h in solutions_reduced if is_minimal(h, solutions_reduced)]\n",
    "    minimal_solutions_full = [lift_solution_to_full(h, len_M, old_to_new) for h in minimal_solutions_reduced]\n",
    "\n",
    "    stats[\"total_solutions_found\"] = len(minimal_solutions_full)\n",
    "    if minimal_solutions_full:\n",
    "        cards = [card(s) for s in minimal_solutions_full]\n",
    "        stats[\"min_cardinality\"] = min(cards)\n",
    "        stats[\"max_cardinality\"] = max(cards)\n",
    "    else:\n",
    "        stats[\"min_cardinality\"] = 0\n",
    "        stats[\"max_cardinality\"] = 0\n",
    "\n",
    "    # --- scrivi output .mhs --- -- SOLO SE HA TROVATO ALMENO UNA SOLUZIONE\n",
    "        \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    output_path = os.path.join(output_dir, base_name + \".mhs\")\n",
    "\n",
    "    # indici delle colonne rimosse (1-based)\n",
    "    removed_1based = [i + 1 for i in removed_indices] if removed_indices else []\n",
    "\n",
    "    write_mhs_file(output_path, os.path.basename(input_path), M, minimal_solutions_full, stats, removed_1based)\n",
    "\n",
    "    return minimal_solutions_full, output_path, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versione corretta ma teniamo anche l'altra si sa mai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGIORNATA\n",
    "def MAIN_COMPITO_2(input_path: str, max_seconds: float = None, output_dir: str = \"outputs\"):\n",
    "    \"\"\"\n",
    "    Wrapper MAIN:\n",
    "      - legge M,N dal file (parse_matrix_file)\n",
    "      - riduce dominio a M'\n",
    "      - esegue la ricerca MHS su M' (utilizza le funzioni CHECK/GENERATE_CHILDREN/... già presenti)\n",
    "      - registra statistiche temporali/spaziali e per-livello\n",
    "      - scrive file .mhs in output_dir con soluzioni rialzate su M\n",
    "    :param input_path: percorso completo del file .matrix di input\n",
    "    :param max_seconds: timeout in secondi (None = nessun timeout)\n",
    "    :param output_dir: directory di output per il file .mhs\n",
    "    :return: (minimal_solutions_full, output_path, stats)\n",
    "    \"\"\"\n",
    "    # --- parsing del file di input e riduzione delle colonne vuote ---\n",
    "    M, N = parse_matrix_files(input_path)          # M: List[str], N: List[Set[str]]\n",
    "    len_M = len(M)\n",
    "    len_N = len(N)\n",
    "\n",
    "    M_prime, N_prime, removed_indices, old_to_new, new_to_old = reduce_domain_remove_empty_cols(M, N)\n",
    "    len_Mp = len(M_prime)\n",
    "\n",
    "    # Livello H_max = max(len_N, len_Mp)\n",
    "    H_max = max(len_N, len_Mp)\n",
    "\n",
    "    # Conversione liste per la funzione CHECK\n",
    "    N_list_prime = [list(s) for s in N_prime]\n",
    "    M_prime_list = list(M_prime)\n",
    "\n",
    "    # dizionario per statistiche\n",
    "    stats: Dict = {\n",
    "        \"input_file\": os.path.basename(input_path),\n",
    "        \"len_M\": len_M,\n",
    "        \"len_Mp\": len_Mp,\n",
    "        \"len_N\": len_N,\n",
    "        \"removed_indices\": removed_indices,\n",
    "        \"H_max\": H_max,\n",
    "        \"start_time\": None,\n",
    "        \"end_time\": None,\n",
    "        \"start_time_str\": None,\n",
    "        \"end_time_str\": None,\n",
    "        \"elapsed_seconds\": None,\n",
    "        \"peak_mem_kb\": None,\n",
    "        \"rss_kb\": None,\n",
    "        \"interrupted\": False,\n",
    "        \"interrupted_level\": None,\n",
    "        \"max_seconds\": max_seconds,\n",
    "        \"level_stats\": {},   # livello -> {'generated', 'checked'}\n",
    "        \"total_solutions_found\": 0,\n",
    "        \"min_cardinality\": None,\n",
    "        \"max_cardinality\": None,\n",
    "    }\n",
    "\n",
    "    # --- start perf tracking ---\n",
    "    start_time = start_perf_tracking()\n",
    "    stats[\"start_time\"] = start_time\n",
    "    stats[\"start_time_str\"] = time.ctime()\n",
    "\n",
    "    h_0 = empty_hypothesis(len_Mp)\n",
    "    current: List[Hypothesis] = [h_0]\n",
    "    solutions_reduced: Set[Hypothesis] = set()\n",
    "\n",
    "    # timeout flags\n",
    "    interrupted = False\n",
    "    interrupted_level = None\n",
    "\n",
    "    level_stats: Dict[int, Dict[str, int]] = {} \n",
    "\n",
    "    # --- ciclo principale algoritmo ---\n",
    "    try:\n",
    "        while current:\n",
    "            next_level: List[Hypothesis] = []\n",
    "\n",
    "            for h in list(current):\n",
    "                # timeout\n",
    "                if max_seconds and (time.perf_counter() - start_time) > max_seconds:\n",
    "                    interrupted = True\n",
    "                    interrupted_level = card(h)\n",
    "                    current = []  # forza uscita\n",
    "                    break\n",
    "\n",
    "                lvl = card(h)\n",
    "                level_stats.setdefault(lvl, {\"generated\": 0, \"checked\": 0})\n",
    "                level_stats[lvl][\"checked\"] += 1\n",
    "\n",
    "                # prune: non generare figli oltre H_max\n",
    "                if lvl >= H_max:\n",
    "                    if CHECK(h, N_list_prime, M_prime_list):\n",
    "                        solutions_reduced.add(h)\n",
    "                    continue\n",
    "\n",
    "                # verifica soluzione su dominio ridotto\n",
    "                if CHECK(h, N_list_prime, M_prime_list):\n",
    "                    solutions_reduced.add(h)\n",
    "                    try:\n",
    "                        current.remove(h)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                elif h == empty_hypothesis(len_Mp):\n",
    "                    children = GENERATE_CHILDREN(h, current)\n",
    "                    nxt_level = lvl + 1\n",
    "                    level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                    level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                    next_level.extend(children)\n",
    "\n",
    "                elif LM1(h) != 1:\n",
    "                    h_s_2 = globalInitial(h)\n",
    "                    current = [h_r for h_r in current if binario(h_r) <= binario(h_s_2)]\n",
    "\n",
    "                    if current:\n",
    "                        h_p = current[0]\n",
    "                        if h_p != h:\n",
    "                            children = GENERATE_CHILDREN(h, current)\n",
    "                            nxt_level = lvl + 1\n",
    "                            level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                            level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                            next_level = MERGE(next_level, children)\n",
    "\n",
    "            current = next_level\n",
    "            stats[\"level_stats\"] = level_stats\n",
    "\n",
    "            if interrupted: \n",
    "                stats[\"interrupted\"] = True\n",
    "                stats[\"interrupted_level\"] = interrupted_level\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        interrupted = True\n",
    "        stats[\"exception\"] = repr(e)\n",
    "\n",
    "    # --- end tracking ---\n",
    "    elapsed, peak_kb, rss_kb = stop_perf_tracking(start_time)\n",
    "    stats[\"end_time\"] = time.perf_counter()\n",
    "    stats[\"end_time_str\"] = time.ctime()\n",
    "    stats[\"elapsed_seconds\"] = elapsed\n",
    "    stats[\"peak_mem_kb\"] = peak_kb\n",
    "    stats[\"rss_kb\"] = rss_kb\n",
    "    stats[\"interrupted\"] = interrupted\n",
    "    stats[\"interrupted_level\"] = interrupted_level\n",
    "    stats[\"level_stats\"] = level_stats\n",
    "\n",
    "    # --- estrai MHS e rialza su dominio M originale ---\n",
    "    minimal_solutions_reduced = [h for h in solutions_reduced if is_minimal(h, solutions_reduced)]\n",
    "    minimal_solutions_full = [lift_solution_to_full(h, len_M, old_to_new) for h in minimal_solutions_reduced]\n",
    "\n",
    "    # --- ORDINA LE SOLUZIONI IN ORDINE DECRESCENTE BINARIO (sx→dx) ---\n",
    "    minimal_solutions_full.sort(key=lambda x: int(\"\".join(str(b) for b in x), 2), reverse=True)\n",
    "\n",
    "    stats[\"total_solutions_found\"] = len(minimal_solutions_full)\n",
    "    if minimal_solutions_full:\n",
    "        cards = [card(s) for s in minimal_solutions_full]\n",
    "        stats[\"min_cardinality\"] = min(cards)\n",
    "        stats[\"max_cardinality\"] = max(cards)\n",
    "    else:\n",
    "        stats[\"min_cardinality\"] = 0\n",
    "        stats[\"max_cardinality\"] = 0\n",
    "\n",
    "    # --- scrivi output .mhs ---\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    output_path = os.path.join(output_dir, base_name + \".mhs\")\n",
    "\n",
    "    removed_1based = [i + 1 for i in removed_indices] if removed_indices else []\n",
    "\n",
    "    write_mhs_file(output_path, os.path.basename(input_path), M, minimal_solutions_full, stats, removed_1based)\n",
    "\n",
    "    return minimal_solutions_full, output_path, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # codice per file singolo\n",
    "\n",
    "# # --- parsing e riduzione dominio ---\n",
    "# # M, N = parse_matrix_files(\"../benchmarks1/74L85.000.matrix\")\n",
    "# # M, N = parse_matrix_files(\"../benchmarks1/74L85.008.matrix\")\n",
    "# M, N = parse_matrix_files(\"../benchmarks1/74L85.002.matrix\")\n",
    "# M_prime, N_prime, removed_indices, old_to_new, new_to_old = reduce_domain_remove_empty_cols(M, N)\n",
    "# print(\"len(M)=\", len(M), \"len(M')=\", len(M_prime), \"len(N)=\", len(N))\n",
    "# print(\"removed (1-based):\", [i+1 for i in removed_indices])\n",
    "\n",
    "# # MAIN con output e timeout impostato a 60s\n",
    "# # solutions, outpath, stats = MAIN(\"../benchmarks1/74L85.000.matrix\", max_seconds=60, output_dir=\"outputs\")\n",
    "# solutions, outpath, stats = MAIN_COMPITO_2(\"../benchmarks1/74L85.002.matrix\", max_seconds=120, output_dir=\"outputs\")\n",
    "# print(\"Output scritto in:\", outpath)\n",
    "# print(\"Soluzioni trovate:\", len(solutions))\n",
    "\n",
    "# for s in solutions:\n",
    "#     elementi = [M[i] for i, bit in enumerate(s) if bit == 1]\n",
    "#     print(f\"{s} -> {elementi}\")\n",
    "\n",
    "# print(\"Stats elapsed (s):\", stats['elapsed_seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faccio le sperimentazioni su:\n",
    "-benchmark1: per ogni classe di file\n",
    "\n",
    "c1908: 98 file\n",
    "74181: 54 file\n",
    "c5315: 248 file\n",
    "c2670: 168 file\n",
    "c1355: 98 file\n",
    "c880: 198 file\n",
    "74L85: 28 file\n",
    "c7552: 176 file\n",
    "c499: 141 file\n",
    "74283: 30 file\n",
    "c432: 45 file\n",
    "74182: 50 file\n",
    "c3540: 36 file\n",
    "c6288: 1 file\n",
    "\n",
    "scelgo una media ragionevole dei file da analizzare\n",
    "e scrivo i risultati in outputs/compito_2/benchmarks1/classe/{un file.txt per ogni file matrix}\n",
    "\n",
    "-benchmark2: per ogni classe di file:\n",
    "c1908: 127 file\n",
    "74181: 54 file\n",
    "c5315: 248 file\n",
    "c2670: 168 file\n",
    "c1355: 98 file\n",
    "c880: 198 file\n",
    "74L85: 28 file\n",
    "c7552: 176 file\n",
    "c499: 141 file\n",
    "74283: 30 file\n",
    "c432: 45 file\n",
    "74182: 50 file\n",
    "c3540: 36 file\n",
    "c6288: 1 file\n",
    "\n",
    "scelgo una media ragionevole dei file da analizzare\n",
    "chiamo il metodo delle permutazioni su ciascun file di ciascuna classe\n",
    "e scrivo i risultati in outputs/compito_2/benchmarks2/classe/{un file.txt per ogni file matrix}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarcks_1_classes = { \"74181\": 20, \"c5315\": 20, \"c2670\": 20, \"c1355\": 20, \"c880\": 20, \"74L85\": 20, \"c7552\": 20, \"c499\": 20, \"74283\": 20, \"c432\": 20, \"74182\": 20, \"c3540\": 20, \"c6288\": 1, }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connessione al broker MQTT e sottoscrizione al topic MESSAGGI. Quando gli arriva un messaggio da parte della Web App, lo intercetta e si ferma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiunto controllo stop flag in GENERATE_CHILDREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GENERATE_CHILDREN(h: Hypothesis, current: List[Hypothesis]):\n",
    "#     global stop_flag\n",
    "#     children = set()\n",
    "\n",
    "#     # Controllo STOP immediato\n",
    "#     if stop_flag:\n",
    "#         return list(children)\n",
    "\n",
    "#     # Caso: ipotesi vuota → genera tutti i vicini a distanza 1\n",
    "#     if h == empty_hypothesis(len(h)):\n",
    "#         for i in range(len(h)):\n",
    "#             if stop_flag:\n",
    "#                 break\n",
    "#             if h[i] == 0:\n",
    "#                 h1 = list(h)\n",
    "#                 h1[i] = 1\n",
    "#                 SET_FIELDS(h1)\n",
    "#                 children.add(tuple(h1))\n",
    "#         return list(children)\n",
    "\n",
    "#     # Mappa per accesso rapido agli indici\n",
    "#     index_map = {tuple(hyp): idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "#     for i in range(LM1(h) - 1):\n",
    "#         if stop_flag:\n",
    "#             break\n",
    "#         if h[i] == 0:\n",
    "#             h1 = list(h)\n",
    "#             h1[i] = 1\n",
    "#             SET_FIELDS(h1)\n",
    "#             PROPAGATE(h, h1)\n",
    "\n",
    "#             h_i = initial(h, h1)\n",
    "#             h_f = final(h, h1)\n",
    "#             count = 0\n",
    "\n",
    "#             # prendo indici in sicurezza\n",
    "#             start_idx = index_map.get(tuple(h_f), 0)\n",
    "#             end_idx   = index_map.get(tuple(h_i), len(current) - 1)\n",
    "\n",
    "#             # scorro su una sottolista di current SENZA modificarla\n",
    "#             for hp in current[start_idx:end_idx + 1]:\n",
    "#                 if stop_flag:\n",
    "#                     break\n",
    "#                 if dist(hp, h1) == 1 and dist(hp, h) == 2:\n",
    "#                     PROPAGATE(hp, h1)\n",
    "#                     count += 1\n",
    "\n",
    "#             if count == card(h) and tuple(h1) != tuple(h):\n",
    "#                 children.add(tuple(h1))\n",
    "\n",
    "#     return list(children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MAIN_COMPITO_2(input_path: str, max_seconds: float = None, output_dir: str = \"outputs\"):\n",
    "#     global stop_flag\n",
    "#     \"\"\"\n",
    "#     Wrapper MAIN:\n",
    "#       - legge M,N dal file (parse_matrix_file)\n",
    "#       - riduce dominio a M'\n",
    "#       - esegue la ricerca MHS su M' (utilizza le funzioni CHECK/GENERATE_CHILDREN/... già presenti)\n",
    "#       - registra statistiche temporali/spaziali e per-livello\n",
    "#       - scrive file .mhs in output_dir con soluzioni rialzate su M\n",
    "#     :param input_path: percorso completo del file .matrix di input\n",
    "#     :param max_seconds: timeout in secondi (None = nessun timeout)\n",
    "#     :param output_dir: directory di output per il file .mhs\n",
    "#     :return: (minimal_solutions_full, output_path, stats)\n",
    "#         - minimal_solutions_full: lista di tuple rappresentanti le soluzioni su M completo\n",
    "#         - output_path: percorso completo del file .mhs generato\n",
    "#         - stats: dizionario con statistiche della computazione\n",
    "#     \"\"\"\n",
    "\n",
    "#     # --- parsing del file di input e riduzione delle colonne vuote ---\n",
    "#     M, N = parse_matrix_files(input_path)          # M: List[str], N: List[Set[str]]\n",
    "#     len_M = len(M)\n",
    "#     len_N = len(N)\n",
    "\n",
    "#     M_prime, N_prime, removed_indices, old_to_new, new_to_old = reduce_domain_remove_empty_cols(M, N)\n",
    "#     len_Mp = len(M_prime)\n",
    "\n",
    "#     # Livello H_max = max(len_N, len_Mp)\n",
    "#     H_max = max(len_N, len_Mp)\n",
    "\n",
    "#     # Conversione liste per la funzione CHECK\n",
    "#     N_list_prime = [list(s) for s in N_prime]\n",
    "#     M_prime_list = list(M_prime)\n",
    "\n",
    "#     # dizionario per statistiche\n",
    "#     stats: Dict = {\n",
    "#         \"input_file\": os.path.basename(input_path),\n",
    "#         \"len_M\": len_M,\n",
    "#         \"len_Mp\": len_Mp,\n",
    "#         \"len_N\": len_N,\n",
    "#         \"removed_indices\": removed_indices,\n",
    "#         \"H_max\": H_max,\n",
    "#         \"start_time\": None,\n",
    "#         \"end_time\": None,\n",
    "#         \"start_time_str\": None,\n",
    "#         \"end_time_str\": None,\n",
    "#         \"elapsed_seconds\": None,\n",
    "#         \"peak_mem_kb\": None,\n",
    "#         \"rss_kb\": None,\n",
    "#         \"interrupted\": False,\n",
    "#         \"interrupted_level\": None,\n",
    "#         \"max_seconds\": max_seconds,\n",
    "#         \"level_stats\": {},   # livello -> {'generated', 'checked'}\n",
    "#         \"total_solutions_found\": 0,\n",
    "#         \"min_cardinality\": None,\n",
    "#         \"max_cardinality\": None,\n",
    "#     }\n",
    "\n",
    "#     # --- start perf tracking ---\n",
    "#     start_time = start_perf_tracking()\n",
    "#     stats[\"start_time\"] = start_time\n",
    "#     stats[\"start_time_str\"] = time.ctime()\n",
    "\n",
    "\n",
    "#     h_0 = empty_hypothesis(len_Mp)\n",
    "#     current: List[Hypothesis] = [h_0]\n",
    "#     solutions_reduced: Set[Hypothesis] = set()\n",
    "\n",
    "#     # timeout flags\n",
    "#     interrupted = False\n",
    "#     interrupted_level = None\n",
    "\n",
    "#     level_stats: Dict[int, Dict[str, int]] = {} \n",
    "\n",
    "#     # --- ciclo principale algoritmo ---\n",
    "#     try:\n",
    "#         while current:\n",
    "#             #Controllo se c'è lo STOP\n",
    "#             if stop_flag: \n",
    "#                 print(\"STOP ricevuto, interrompo il benchmark!\")\n",
    "#                 interrupted = True\n",
    "#                 break\n",
    "\n",
    "#             next_level: List[Hypothesis] = []\n",
    "\n",
    "#             for h in list(current):\n",
    "#                 if stop_flag:\n",
    "#                     interrupted = True\n",
    "#                     break\n",
    "#                 # timeout\n",
    "#                 if max_seconds and (time.perf_counter() - start_time) > max_seconds:\n",
    "#                     interrupted = True\n",
    "#                     interrupted_level = card(h)\n",
    "#                     current = []  # forza uscita\n",
    "#                     break\n",
    "\n",
    "#                 lvl = card(h)\n",
    "#                 level_stats.setdefault(lvl, {\"generated\": 0, \"checked\": 0})\n",
    "#                 level_stats[lvl][\"checked\"] += 1\n",
    "\n",
    "#                 # prune: non generare figli oltre H_max\n",
    "#                 if lvl >= H_max:\n",
    "#                     # verifico se è soluzione su dominio ridotto \n",
    "#                     if CHECK(h, N_list_prime, M_prime_list):\n",
    "#                         solutions_reduced.add(h)\n",
    "#                     continue\n",
    "\n",
    "#                 # verifica soluzione su dominio ridotto\n",
    "#                 if CHECK(h, N_list_prime, M_prime_list):\n",
    "#                     solutions_reduced.add(h)\n",
    "#                     try:\n",
    "#                         current.remove(h)\n",
    "#                     except ValueError:\n",
    "#                         pass\n",
    "\n",
    "#                 elif h == empty_hypothesis(len_Mp):\n",
    "#                     children = GENERATE_CHILDREN(h, current)\n",
    "#                     nxt_level = lvl + 1\n",
    "#                     level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "#                     level_stats[nxt_level][\"generated\"] += len(children)\n",
    "#                     next_level.extend(children)\n",
    "\n",
    "#                 elif LM1(h) != 1:\n",
    "#                     h_s_2 = globalInitial(h)\n",
    "#                     # filtra current\n",
    "#                     current = [h_r for h_r in current if binario(h_r) <= binario(h_s_2)]\n",
    "\n",
    "#                     if current:\n",
    "#                         h_p = current[0]\n",
    "#                         if h_p != h:\n",
    "#                             children = GENERATE_CHILDREN(h, current)\n",
    "#                             nxt_level = lvl + 1\n",
    "#                             level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "#                             level_stats[nxt_level][\"generated\"] += len(children)\n",
    "#                             next_level = MERGE(next_level, children)\n",
    "\n",
    "#             # livello successivo esplorazione\n",
    "#             current = next_level\n",
    "#             stats[\"level_stats\"] = level_stats\n",
    "\n",
    "#             # controllo interruzione per statistiche\n",
    "#             if interrupted: \n",
    "#                 stats[\"interrupted\"] = True\n",
    "#                 stats[\"interrupted_level\"] = interrupted_level\n",
    "#                 break\n",
    "\n",
    "#     except Exception as e:\n",
    "#         interrupted = True\n",
    "#         stats[\"exception\"] = repr(e)\n",
    "\n",
    "#     # --- end tracking ---\n",
    "#     elapsed, peak_kb, rss_kb = stop_perf_tracking(start_time)\n",
    "#     stats[\"end_time\"] = time.perf_counter()\n",
    "#     stats[\"end_time_str\"] = time.ctime()\n",
    "#     stats[\"elapsed_seconds\"] = elapsed\n",
    "#     stats[\"peak_mem_kb\"] = peak_kb\n",
    "#     stats[\"rss_kb\"] = rss_kb\n",
    "#     stats[\"interrupted\"] = interrupted\n",
    "#     stats[\"interrupted_level\"] = interrupted_level\n",
    "#     stats[\"level_stats\"] = level_stats\n",
    "\n",
    "#     # --- estrai MHS e rialza su dominio M originale ---\n",
    "#     minimal_solutions_reduced = [h for h in solutions_reduced if is_minimal(h, solutions_reduced)]\n",
    "#     minimal_solutions_full = [lift_solution_to_full(h, len_M, old_to_new) for h in minimal_solutions_reduced]\n",
    "\n",
    "#     stats[\"total_solutions_found\"] = len(minimal_solutions_full)\n",
    "#     if minimal_solutions_full:\n",
    "#         cards = [card(s) for s in minimal_solutions_full]\n",
    "#         stats[\"min_cardinality\"] = min(cards)\n",
    "#         stats[\"max_cardinality\"] = max(cards)\n",
    "#     else:\n",
    "#         stats[\"min_cardinality\"] = 0\n",
    "#         stats[\"max_cardinality\"] = 0\n",
    "\n",
    "#     # --- scrivi output .mhs ---\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "#     output_path = os.path.join(output_dir, base_name + \".mhs\")\n",
    "\n",
    "#     # indici delle colonne rimosse (1-based)\n",
    "#     removed_1based = [i + 1 for i in removed_indices] if removed_indices else []\n",
    "\n",
    "#     write_mhs_file(output_path, os.path.basename(input_path), M, minimal_solutions_full, stats, removed_1based)\n",
    "\n",
    "#     return minimal_solutions_full, output_path, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTE CONNESSIONE CON BROKER MQTT CON METODI NUOVI AGGIORNATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versione corretta\n",
    "def GENERATE_CHILDREN_aggiornato(h: Hypothesis, current: List[Hypothesis]) -> List[Hypothesis]:\n",
    "    global stop_flag\n",
    "    \"\"\"\n",
    "    Genera i figli dell'ipotesi h in ordine da sinistra a destra,\n",
    "    seguendo la logica del metodo Node.generate_children, e mantenendo SET_FIELDS.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Controllo STOP immediato\n",
    "    if stop_flag:\n",
    "        return children\n",
    "\n",
    "    # Caso iniziale: ipotesi vuota → genera tutti i vicini a distanza 1\n",
    "    if h == empty_hypothesis(len(h)):\n",
    "        for i in range(len(h)):\n",
    "            if stop_flag:\n",
    "                break\n",
    "            if h[i] == 0:\n",
    "                h1 = list(h)\n",
    "                h1[i] = 1\n",
    "                SET_FIELDS(h1)\n",
    "                children.append(tuple(h1))\n",
    "        return children\n",
    "\n",
    "    # --- Costruisco una mappa delle posizioni delle ipotesi correnti\n",
    "    index_map = {tuple(hyp): idx for idx, hyp in enumerate(current)}\n",
    "\n",
    "    # --- Ciclo da sinistra a destra\n",
    "    for i in range(LM1(h) - 1):\n",
    "        if stop_flag:\n",
    "            break\n",
    "        if h[i] == 0:\n",
    "            h1 = list(h)\n",
    "            h1[i] = 1\n",
    "            SET_FIELDS(h1)\n",
    "            h1 = tuple(PROPAGATE(h, h1))\n",
    "\n",
    "            # Calcolo hi (iniziale) e hf (finale)\n",
    "            hi = initial(h, h1)\n",
    "            hf = final(h, h1)\n",
    "\n",
    "            # Recupero posizioni in current\n",
    "            try:\n",
    "                pos_hi = index_map[tuple(hi)]\n",
    "            except KeyError:\n",
    "                pos_hi = len(current) - 1\n",
    "            try:\n",
    "                pos_hf = index_map[tuple(hf)]\n",
    "            except KeyError:\n",
    "                pos_hf = 0\n",
    "\n",
    "            count = 0\n",
    "            for hp in current[pos_hf:pos_hi + 1]:\n",
    "                if stop_flag:\n",
    "                    break\n",
    "                if dist(hp, h1) == 1 and dist(hp, h) == 2:\n",
    "                    h1 = tuple(PROPAGATE(hp, h1))\n",
    "                    count += 1\n",
    "\n",
    "            # Condizione di ammissibilità \n",
    "            # if count == card(h) and tuple(h1) != tuple(h):\n",
    "            #     children.append(tuple(h1))\n",
    "\n",
    "            if count == card(h):\n",
    "                children.append(tuple(h1))\n",
    "\n",
    "    # Ordina in (sinistra → destra)\n",
    "    children.sort(key=binario)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGIORNATA\n",
    "def MAIN_COMPITO_2_aggiornato(input_path: str, max_seconds: float = None, output_dir: str = \"outputs\"):\n",
    "    global stop_flag\n",
    "    \"\"\"\n",
    "    Wrapper MAIN:\n",
    "      - legge M,N dal file (parse_matrix_file)\n",
    "      - riduce dominio a M'\n",
    "      - esegue la ricerca MHS su M' (utilizza le funzioni CHECK/GENERATE_CHILDREN/... già presenti)\n",
    "      - registra statistiche temporali/spaziali e per-livello\n",
    "      - scrive file .mhs in output_dir con soluzioni rialzate su M\n",
    "    :param input_path: percorso completo del file .matrix di input\n",
    "    :param max_seconds: timeout in secondi (None = nessun timeout)\n",
    "    :param output_dir: directory di output per il file .mhs\n",
    "    :return: (minimal_solutions_full, output_path, stats)\n",
    "    \"\"\"\n",
    "    # --- parsing del file di input e riduzione delle colonne vuote ---\n",
    "    M, N = parse_matrix_files(input_path)          # M: List[str], N: List[Set[str]]\n",
    "    len_M = len(M)\n",
    "    len_N = len(N)\n",
    "\n",
    "    M_prime, N_prime, removed_indices, old_to_new, new_to_old = reduce_domain_remove_empty_cols(M, N)\n",
    "    len_Mp = len(M_prime)\n",
    "\n",
    "    # Livello H_max = max(len_N, len_Mp)\n",
    "    H_max = max(len_N, len_Mp)\n",
    "\n",
    "    # Conversione liste per la funzione CHECK\n",
    "    N_list_prime = [list(s) for s in N_prime]\n",
    "    M_prime_list = list(M_prime)\n",
    "\n",
    "    # dizionario per statistiche\n",
    "    stats: Dict = {\n",
    "        \"input_file\": os.path.basename(input_path),\n",
    "        \"len_M\": len_M,\n",
    "        \"len_Mp\": len_Mp,\n",
    "        \"len_N\": len_N,\n",
    "        \"removed_indices\": removed_indices,\n",
    "        \"H_max\": H_max,\n",
    "        \"start_time\": None,\n",
    "        \"end_time\": None,\n",
    "        \"start_time_str\": None,\n",
    "        \"end_time_str\": None,\n",
    "        \"elapsed_seconds\": None,\n",
    "        \"peak_mem_kb\": None,\n",
    "        \"rss_kb\": None,\n",
    "        \"interrupted\": False,\n",
    "        \"interrupted_level\": None,\n",
    "        \"max_seconds\": max_seconds,\n",
    "        \"level_stats\": {},   # livello -> {'generated', 'checked'}\n",
    "        \"total_solutions_found\": 0,\n",
    "        \"min_cardinality\": None,\n",
    "        \"max_cardinality\": None,\n",
    "    }\n",
    "\n",
    "    # --- start perf tracking ---\n",
    "    start_time = start_perf_tracking()\n",
    "    stats[\"start_time\"] = start_time\n",
    "    stats[\"start_time_str\"] = time.ctime()\n",
    "\n",
    "    h_0 = empty_hypothesis(len_Mp)\n",
    "    current: List[Hypothesis] = [h_0]\n",
    "    solutions_reduced: Set[Hypothesis] = set()\n",
    "\n",
    "    # timeout flags\n",
    "    interrupted = False\n",
    "    interrupted_level = None\n",
    "\n",
    "    level_stats: Dict[int, Dict[str, int]] = {} \n",
    "\n",
    "    # --- ciclo principale algoritmo ---\n",
    "    try:\n",
    "        while current:\n",
    "            #Controllo se c'è lo STOP\n",
    "            if stop_flag: \n",
    "                print(\"STOP ricevuto, interrompo il benchmark!\")\n",
    "                interrupted = True\n",
    "                break\n",
    "\n",
    "            next_level: List[Hypothesis] = []\n",
    "\n",
    "            for h in list(current):\n",
    "                if stop_flag:\n",
    "                    interrupted = True\n",
    "                    break\n",
    "                # timeout\n",
    "                if max_seconds and (time.perf_counter() - start_time) > max_seconds:\n",
    "                    interrupted = True\n",
    "                    interrupted_level = card(h)\n",
    "                    current = []  # forza uscita\n",
    "                    break\n",
    "\n",
    "                lvl = card(h)\n",
    "                level_stats.setdefault(lvl, {\"generated\": 0, \"checked\": 0})\n",
    "                level_stats[lvl][\"checked\"] += 1\n",
    "\n",
    "                # prune: non generare figli oltre H_max\n",
    "                if lvl >= H_max:\n",
    "                    if CHECK(h, N_list_prime, M_prime_list):\n",
    "                        solutions_reduced.add(h)\n",
    "                    continue\n",
    "\n",
    "                # verifica soluzione su dominio ridotto\n",
    "                if CHECK(h, N_list_prime, M_prime_list):\n",
    "                    solutions_reduced.add(h)\n",
    "                    try:\n",
    "                        current.remove(h)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                elif h == empty_hypothesis(len_Mp):\n",
    "                    children = GENERATE_CHILDREN_aggiornato(h, current)\n",
    "                    nxt_level = lvl + 1\n",
    "                    level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                    level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                    next_level.extend(children)\n",
    "\n",
    "                elif LM1(h) != 1:\n",
    "                    h_s_2 = globalInitial(h)\n",
    "                    current = [h_r for h_r in current if binario(h_r) <= binario(h_s_2)]\n",
    "\n",
    "                    if current:\n",
    "                        h_p = current[0]\n",
    "                        if h_p != h:\n",
    "                            children = GENERATE_CHILDREN_aggiornato(h, current)\n",
    "                            nxt_level = lvl + 1\n",
    "                            level_stats.setdefault(nxt_level, {\"generated\": 0, \"checked\": 0})\n",
    "                            level_stats[nxt_level][\"generated\"] += len(children)\n",
    "                            next_level = MERGE(next_level, children)\n",
    "\n",
    "            current = next_level\n",
    "            stats[\"level_stats\"] = level_stats\n",
    "\n",
    "            if interrupted: \n",
    "                stats[\"interrupted\"] = True\n",
    "                stats[\"interrupted_level\"] = interrupted_level\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        interrupted = True\n",
    "        stats[\"exception\"] = repr(e)\n",
    "\n",
    "    # --- end tracking ---\n",
    "    elapsed, peak_kb, rss_kb = stop_perf_tracking(start_time)\n",
    "    stats[\"end_time\"] = time.perf_counter()\n",
    "    stats[\"end_time_str\"] = time.ctime()\n",
    "    stats[\"elapsed_seconds\"] = elapsed\n",
    "    stats[\"peak_mem_kb\"] = peak_kb\n",
    "    stats[\"rss_kb\"] = rss_kb\n",
    "    stats[\"interrupted\"] = interrupted\n",
    "    stats[\"interrupted_level\"] = interrupted_level\n",
    "    stats[\"level_stats\"] = level_stats\n",
    "\n",
    "    # --- estrai MHS e rialza su dominio M originale ---\n",
    "    minimal_solutions_reduced = [h for h in solutions_reduced if is_minimal(h, solutions_reduced)]\n",
    "    minimal_solutions_full = [lift_solution_to_full(h, len_M, old_to_new) for h in minimal_solutions_reduced]\n",
    "\n",
    "    # --- ORDINA LE SOLUZIONI IN ORDINE DECRESCENTE BINARIO (sx→dx) ---\n",
    "    minimal_solutions_full.sort(key=lambda x: int(\"\".join(str(b) for b in x), 2), reverse=True)\n",
    "\n",
    "    stats[\"total_solutions_found\"] = len(minimal_solutions_full)\n",
    "    if minimal_solutions_full:\n",
    "        cards = [card(s) for s in minimal_solutions_full]\n",
    "        stats[\"min_cardinality\"] = min(cards)\n",
    "        stats[\"max_cardinality\"] = max(cards)\n",
    "    else:\n",
    "        stats[\"min_cardinality\"] = 0\n",
    "        stats[\"max_cardinality\"] = 0\n",
    "\n",
    "    # --- scrivi output .mhs ---    \n",
    "    if stats[\"total_solutions_found\"] > 0:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "        output_path = os.path.join(output_dir, base_name + \".mhs\")\n",
    "\n",
    "        removed_1based = [i + 1 for i in removed_indices] if removed_indices else []\n",
    "\n",
    "        write_mhs_file(output_path, os.path.basename(input_path), M, minimal_solutions_full, stats, removed_1based)\n",
    "\n",
    "        return minimal_solutions_full, output_path, stats\n",
    "    else:\n",
    "        return [], None, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gestione RISPOSTA che mando alla WebApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "def risposta(comando_ricevuto, GUID):\n",
    "\n",
    "    global benchmark_in_corso, benchmark_owner\n",
    "\n",
    "    #Se il benchmarck è fermo \n",
    "    if not benchmark_in_corso:\n",
    "        if comando_ricevuto == 1: #start\n",
    "            esito = \"COMANDO ACCETTATO\"\n",
    "        elif comando_ricevuto == 2:\n",
    "            esito = \"COMANDO RIFIUTATO\"\n",
    "        else:\n",
    "            esito = \"COMANDO RIFIUTATO\" \n",
    "\n",
    "    #Se sil benchmarck è in corso e ottengo START --> esito: no e rimango in = RUNNING\n",
    "    else:\n",
    "        if benchmark_in_corso:\n",
    "            if comando_ricevuto == 1:\n",
    "                esito = \"COMANDO RIFIUTATO\"\n",
    "            elif comando_ricevuto == 2:\n",
    "            #ricevo uno STOP \n",
    "                esito = \"COMANDO ACCETTATO\"\n",
    "            else:\n",
    "                esito = \"COMANDO RIFIUTATO\" \n",
    "\n",
    "  \n",
    "    return esito\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "import sys\n",
    "import json\n",
    "import threading\n",
    "\n",
    "stop_flag = False  # variabile globale\n",
    "start_flag = False\n",
    "\n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    global stop_flag\n",
    "    global start_flag\n",
    "    global stato_corrente\n",
    "    global benchmark_in_corso\n",
    "    global benchmark_owner\n",
    "\n",
    "    payload = msg.payload.decode()\n",
    "\n",
    "    data = json.loads(payload)\n",
    "    codice_comando = data[\"codice_comando\"]\n",
    "    GUID = data['GUID']\n",
    "\n",
    "    #print(f\"Messaggio ricevuto: {payload}\")\n",
    "    esito = risposta(codice_comando, GUID)\n",
    "    \n",
    "\n",
    "\n",
    "    if esito == \"COMANDO ACCETTATO\": \n",
    "        # Se un benchmark è già in corso e arriva un START\n",
    "        if codice_comando == 1:\n",
    "            if benchmark_in_corso:\n",
    "                # Rispondo con rifiuto\n",
    "                ANSW = {\n",
    "                    \"Stato corrente\": stato_corrente,\n",
    "                    \"esito\": \"COMANDO RIFIUTATO\"\n",
    "                }\n",
    "                client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "                print(f\"[{GUID}] START rifiutato, benchmark già in corso\")\n",
    "                return\n",
    "            \n",
    "            # Se un benchmark NON è in corso e arriva un START\n",
    "            else:\n",
    "                start_flag = True\n",
    "                benchmark_in_corso = True\n",
    "                benchmark_owner = GUID  \n",
    "\n",
    "                # Rispondo positivo\n",
    "                ANSW = {\n",
    "                    \"Stato corrente\": \"RUNNING\",\n",
    "                    \"esito\": \"COMANDO ACCETTATO\"\n",
    "                }\n",
    "\n",
    "                #Aggiorno lo stato corrente\n",
    "                stato_corrente = ANSW['Stato corrente']\n",
    "\n",
    "                client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "                print(f\"[{GUID}] COMANDO START ricevuto\")\n",
    "\n",
    "\n",
    "                # Avvia il benchmark in un thread separato con wrapper\n",
    "                threading.Thread(\n",
    "                    target=run_benchmark_wrapper,\n",
    "                    args=(GUID, client),\n",
    "                    daemon=True\n",
    "                ).start()\n",
    "        \n",
    "       \n",
    "        elif codice_comando == 2: #Ricevo lo STOP\n",
    "            if not benchmark_in_corso:\n",
    "\n",
    "                ANSW = {\n",
    "                    \"Stato corrente\": \"STAND_BY\",\n",
    "                    \"esito\": \"COMANDO RIFIUTATO\"\n",
    "                }\n",
    "\n",
    "                client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "                print(f\"[{GUID}] COMANDO STOP rifiutato, NESSUN BENCHMARCK IN CORSO\")\n",
    "                return\n",
    "\n",
    "            else: #se c'è un becnhmarck in corso, solo chi lo ha avviato può terminarlo\n",
    "                if GUID != benchmark_owner:\n",
    "                    stop_flag = False\n",
    "                \n",
    "                    ANSW = {\n",
    "                        \"Stato corrente\": \"STAND_BY\",\n",
    "                        \"esito\": \"COMANDO RIFIUTATO: NON AUTORIZZATO\"\n",
    "                    }\n",
    "                    client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "                    print(f\"[{GUID}] STOP rifiutato: benchmark avviato da {benchmark_owner}\")\n",
    "                    return\n",
    "        \n",
    "                else:\n",
    "                    stop_flag = True\n",
    "                    benchmark_in_corso = False\n",
    "                    benchmark_owner = None\n",
    "                    stato_corrente = \"STAND_BY\"\n",
    "\n",
    "                    ANSW = {\n",
    "                        \"Stato corrente\": stato_corrente,\n",
    "                        \"esito\": \"COMANDO ACCETTATO\"\n",
    "                    }\n",
    "                    client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "                    print(f\"[{GUID}] COMANDO STOP accettato → benchmark interrotto\")\n",
    "    else:\n",
    "        #COMANDO RIFIUTATO\n",
    "        ANSW = {\n",
    "                \"Stato corrente\": \"STAND_BY\",\n",
    "                \"esito\": \"COMANDO RIFIUTATO\"\n",
    "                }\n",
    "        \n",
    "        client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "\n",
    "    #client.publish(\"ANSWER\", json.dumps(ANSW))\n",
    "    #client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "\n",
    "\n",
    "\n",
    "def run_benchmark_wrapper(GUID, client):\n",
    "    global benchmark_in_corso, stop_flag\n",
    "    try:\n",
    "        run_benchmark(\"../benchmarks1\", \"output/compito_2/benchmarks1\", benchmarcks_1_classes)\n",
    "    finally:\n",
    "        benchmark_in_corso = False  # libero il benchmark\n",
    "        stop_flag = False  # reset stop\n",
    "        ANSW = {\n",
    "            \"Stato corrente\": stato_corrente,\n",
    "            \"esito\": \"ELABORAZIONE TERMINATA\"\n",
    "        }\n",
    "        client.publish(f\"ANSWER/{GUID}\", json.dumps(ANSW))\n",
    "        print(f\"[{GUID}] Elaborazione completata, benchmark libero\")\n",
    "\n",
    "\n",
    "import shutil\n",
    "def run_benchmark(benchmark_folder: str, output_root: str, classes: dict):\n",
    "    global stop_flag\n",
    "\n",
    "    if os.path.exists(\"output\"):\n",
    "        shutil.rmtree(\"output\")  # cancella la cartella e il suo contenuto\n",
    "        os.makedirs(\"output\")    # la ricrea vuota\n",
    "\n",
    "        print(\"\\nCartella svuotata con successo -- INIZIO NUOVA ELABORAZIONE --\\n\")\n",
    "\n",
    "    \n",
    "    benchmark_folder = Path(benchmark_folder)\n",
    "    output_root = Path(output_root)\n",
    "\n",
    "    for classe, n_files in classes.items():\n",
    "        if stop_flag: \n",
    "            print(\"Esecuzione sul benchmark interrotta!\")\n",
    "            return\n",
    "\n",
    "        all_files = list(benchmark_folder.glob(f\"{classe}.*.matrix\"))\n",
    "        if not all_files:\n",
    "            continue\n",
    "        \n",
    "        selected_files = random.sample(all_files, min(n_files, len(all_files)))\n",
    "\n",
    "        for file in selected_files:\n",
    "            if stop_flag:\n",
    "                print(\"Esecuzione interrotta durante l'elaborazione dei file!\")\n",
    "                return\n",
    "\n",
    "            # Esecuzione algoritmo Main\n",
    "            sols, path, stats = MAIN_COMPITO_2_aggiornato(file, max_seconds=120)\n",
    "\n",
    "            # Crea le cartelle solo se ci sono soluzioni\n",
    "            if sols:\n",
    "                output_folder = output_root / classe\n",
    "                output_folder_file = output_folder / file.stem\n",
    "                os.makedirs(output_folder_file, exist_ok=True)\n",
    "                # Ora scrivi l'output nel posto giusto\n",
    "                write_mhs_file(\n",
    "                    output_folder_file / f\"{file.stem}.mhs\",\n",
    "                    os.path.basename(file),\n",
    "                    [],\n",
    "                    sols,\n",
    "                    stats,\n",
    "                    []\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/prfvvfkj45dc_ffn6cf1hcxm0000gn/T/ipykernel_17612/2861882018.py:1: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client = mqtt.Client()\n"
     ]
    }
   ],
   "source": [
    "client = mqtt.Client()\n",
    "client.on_message = on_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.33\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "def get_local_ip():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    try:\n",
    "        # l'indirizzo non deve essere raggiungibile; serve solo per ottenere l'IP locale\n",
    "        s.connect((\"8.8.8.8\", 80))\n",
    "        return s.getsockname()[0]\n",
    "    except Exception:\n",
    "        return \"127.0.0.1\"\n",
    "    finally:\n",
    "        s.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(get_local_ip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIP = get_local_ip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Client MQTT fermato manualmente.\n",
      "Connessione chiusa con successo.\n"
     ]
    }
   ],
   "source": [
    "stop_flag = False\n",
    "start_flag = False\n",
    "benchmark_in_corso = False\n",
    "benchmark_owner = None\n",
    "\n",
    "stato_corrente = \"STAND_BY\"\n",
    "\n",
    "#client.connect(\"192.168.1.22\", 1883)\n",
    "\n",
    "client.connect(myIP, 1883)\n",
    "\n",
    "client.subscribe(\"MESSAGGI\")\n",
    "\n",
    "try:\n",
    "    client.loop_forever()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Client MQTT fermato manualmente.\")\n",
    "    client.disconnect()\n",
    "    print(\"Connessione chiusa con successo.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
